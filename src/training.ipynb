{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Sampler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on GPU. This is important so things run faster.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU.\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset (Dataset):\n",
    "    def __init__(self,train,size,data_path='../data'):  \n",
    "        self.size = size\n",
    "        data_path = os.path.join(data_path, 'train' if train else 'test')\n",
    "        image_classes = [os.path.split(d)[1] for d in glob.glob(data_path +'/*') if os.path.isdir(d)]\n",
    "        image_classes.sort()\n",
    "        self.name_to_label = {c: id for id, c in enumerate(image_classes)}\n",
    "        self.image_paths = glob.glob(data_path + '/*/*.npy')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) #len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):        \n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = np.load(image_path)\n",
    "        c = os.path.split(os.path.split(image_path)[0])[1]\n",
    "        y = self.name_to_label[c]\n",
    "\n",
    "        image = image[:,:,:7]\n",
    "        #create a simple mask, and make everything else 0\n",
    "        mask = image[:,:,4].copy()\n",
    "        #fix divide by zero\n",
    "#         mask[image[:,:,4]/image[:,:,1] < 1] = 0 \n",
    "#         mask[image[:,:,4]/image[:,:,1] >= 1] = 1\n",
    "        \n",
    "        mask[image[:,:,4] < 35] = 0 \n",
    "        mask[image[:,:,4] >= 35] = 1\n",
    "        image[mask==0] = 0\n",
    "        \n",
    "        image = cv2.resize(image,self.size,interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        X = transforms.functional.to_tensor(image)\n",
    "        return X,y\n",
    "    \n",
    "    def get_image_paths(self):\n",
    "        return self.image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=(64,128)\n",
    "train_set = dataset(train=True,size=size)\n",
    "test_set = dataset(train=False,size=size)\n",
    "\n",
    "batch_size = 512\n",
    "weights = []\n",
    "\n",
    "train_paths = train_set.get_image_paths()\n",
    "oat_length = len(os.listdir('../data/train/Oat'))\n",
    "wheat_length = len(os.listdir('../data/train/Wheat'))\n",
    "rye_length = len(os.listdir('../data/train/Rye'))\n",
    "broken_length = len(os.listdir('../data/train/Broken'))\n",
    "barley_length = len(os.listdir('../data/train/Barley'))\n",
    "\n",
    "for file in train_paths:\n",
    "    label = os.path.split(os.path.split(file)[0])[1]\n",
    "    if label == 'Oat':\n",
    "        weights.append(0.2/oat_length)\n",
    "    elif label == \"Wheat\":\n",
    "        weights.append(0.2/wheat_length)\n",
    "    elif label == \"Rye\":\n",
    "        weights.append(0.2/rye_length)\n",
    "    elif label == \"Broken\":\n",
    "        weights.append(0.2/broken_length)\n",
    "    else:\n",
    "        weights.append(0.2/barley_length)\n",
    "weights = torch.FloatTensor(weights)\n",
    "sampler = WeightedRandomSampler(weights=weights,num_samples=len(train_set),replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size,sampler=sampler,num_workers=0)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        \n",
    "        self.w1 = nn.Conv2d(in_channels=n_features,out_channels=n_features,kernel_size=3,stride=1,padding=1)\n",
    "        self.w2 = nn.Conv2d(in_channels=n_features,out_channels=n_features,kernel_size=3,stride=1,padding=1)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.w1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.w2(x)\n",
    "        x = x+identity\n",
    "        out = self.activation(x)\n",
    "        return out\n",
    "    \n",
    "class SE_ResNetBlock(nn.Module):\n",
    "    def __init__(self, n_features,r):\n",
    "        super(SE_ResNetBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=n_features,out_channels=n_features,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=n_features,out_channels=n_features,kernel_size=3,stride=1,padding=1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.globalpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
    "        self.fc = nn.Conv2d(in_channels=n_features,out_channels=n_features//r,kernel_size=1,stride=1,padding=0) #nn.Linear(in_features=n_features,out_features=n_features//r) \n",
    "        self.fc2 = nn.Conv2d(in_channels=n_features//r,out_channels=n_features,kernel_size=1,stride=1,padding=0) #nn.Linear(in_features=n_features//r,out_features=n_features)\n",
    "        self.gate = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        out = self.conv1(x)\n",
    "        \n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        se = self.globalpool(out) #.unsqueeze(-1).unsqueeze(-1) add if using nn.linear\n",
    "        se = self.fc(se)\n",
    "        se = self.activation(se)\n",
    "        se = self.fc2(se)\n",
    "        se = self.gate(se)\n",
    "        \n",
    "        out = (out*se)+identity\n",
    "        out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define network\n",
    "class SE_ResNet(nn.Module):\n",
    "    def __init__(self, n_in, n_features, num_blocks=2,r=8):\n",
    "        super(SE_ResNet, self).__init__()\n",
    "        #First conv layers needs to output the desired number of features.\n",
    "        conv_layers =[nn.Conv2d(n_in, n_features, kernel_size=3, stride=1, padding=1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Conv2d(n_features,n_features,3,1,1),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d(2,2), #128x64 -> 64x32\n",
    "                      nn.Conv2d(n_features,2*n_features,3,1,1),\n",
    "                      nn.ReLU()]\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            conv_layers.append(SE_ResNetBlock(2*n_features,r))\n",
    "            \n",
    "        conv_layers.append(nn.Sequential(nn.MaxPool2d(2,2),\n",
    "                            nn.Conv2d(2*n_features, 4*n_features, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU())) #64x32 -> 32x16\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            conv_layers.append(SE_ResNetBlock(4*n_features,r))\n",
    "            \n",
    "        conv_layers.append(nn.Sequential(nn.MaxPool2d(2,2),\n",
    "                            nn.Conv2d(4*n_features, 8*n_features, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.ReLU())) #32x16 ->16x8\n",
    "        for i in range(num_blocks):\n",
    "            conv_layers.append(SE_ResNetBlock(8*n_features,r))\n",
    "        \n",
    "        self.blocks = nn.Sequential(*conv_layers)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(16*8*8*n_features, 2048),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(2048, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512,5))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        #reshape x so it becomes flat, except for the first dimension (which is the minibatch)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal(outputs,targets,alpha=1,gamma=2):\n",
    "    ce_loss = F.cross_entropy(outputs, targets, reduction='none') # important to add reduction='none' to keep per-batch-item loss\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal_loss = (alpha * (1-pt)**gamma * ce_loss).mean() # mean over the batch\n",
    "    return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the training as a function.\n",
    "def train(model, optimizer, num_epochs=10):\n",
    "    train_acc_all = []\n",
    "    test_acc_all = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        #For each epoch\n",
    "        train_correct = 0\n",
    "        for minibatch_no, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #Zero the gradients computed for each weight\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass your image through the network\n",
    "            output = model(data)\n",
    "            #Compute the loss\n",
    "            loss = focal(output,target) #F.nll_loss(torch.log(output), target)\n",
    "            #Backward pass through the network\n",
    "            loss.backward()\n",
    "            #Update the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Compute how many were correctly classified\n",
    "            predicted = output.argmax(1)\n",
    "            train_correct += (target==predicted).sum().cpu().item()\n",
    "            \n",
    "            #Remove mini-batch from memory\n",
    "            del data, target, loss\n",
    "        #Comput the test accuracy\n",
    "        test_correct = 0\n",
    "        model.eval()\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(data)\n",
    "            predicted = output.argmax(1).cpu()\n",
    "            test_correct += (target==predicted).sum().item()\n",
    "        train_acc = train_correct/len(train_set)\n",
    "        test_acc = test_correct/len(test_set)\n",
    "        train_acc_all.append(train_acc)\n",
    "        test_acc_all.append(test_acc)\n",
    "        print(\"Accuracy train: {train:.1f}%\\t test: {test:.1f}%\".format(test=100*test_acc, train=100*train_acc))\n",
    "    return test_acc_all, train_acc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e83bd96b7b4d07997c7213fa36428f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy train: 19.7%\t test: 1.5%\n"
     ]
    }
   ],
   "source": [
    "model = SE_ResNet(n_in=7,n_features=8).float()\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(),lr=1e-3)\n",
    "test_acc_all,train_acc_all = train(model,optimizer,num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save model\n",
    "# today = datetime.today()\n",
    "# torch.save(model.state_dict(), '../Models/SEResNet-{date}'.format(date=today.strftime(\"%I%p-%d-%h\")))\n",
    "# np.save('../Models/test_res_{}'.format(today.strftime(\"%I%p-%d-%h\")),test_acc_all)\n",
    "# np.save('../Models/train_res_{}'.format(today.strftime(\"%I%p-%d-%h\")),train_acc_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
